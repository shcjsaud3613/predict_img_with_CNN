{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_img_with_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgr/AMZX9C3rinml2bzWco",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shcjsaud3613/predict_img_with_CNN/blob/main/predict_img_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T79zY923wa3U"
      },
      "source": [
        "# CNN을 통한 단일 이미지 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUi36Rhgwkk-"
      },
      "source": [
        "## Google Colab 링크\n",
        "\n",
        "https://colab.research.google.com/drive/1LO9LJAGce41EhLOy-BcpjHAZvry6b6JG#scrollTo=U8-TLsKCvwF8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z_QgYoawzj3"
      },
      "source": [
        "**학습 데이터세트는 AI Hub에서 신청하여 받았고, 저작자는 한국지능정보사회진흥원이다.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvD1w6-Mx0Eh"
      },
      "source": [
        "## 참고자료"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Ky2FRmx3P2"
      },
      "source": [
        "https://lsjsj92.tistory.com/387"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0-tUvIM-2Wn"
      },
      "source": [
        "## 구글 드라이브 마운드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zutP5YdG-9Wx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hie9WPsxL-F"
      },
      "source": [
        "## 데이터 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umJqPKKjxPU1"
      },
      "source": [
        "먼저 이미지를 배열화시킨다.\n",
        "\n",
        "다음 이미지를 훈련 데이터, 테스트 데이터로 나눈다.\n",
        "\n",
        "이후 numpy 형태로 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8-TLsKCvwF8"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob, sys, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHiCcjrl_PJl"
      },
      "source": [
        "## 데이터세트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI8OJnrm_5DZ",
        "outputId": "d5622332-9cbc-4d38-dfea-18f5c1ca2873"
      },
      "source": [
        "!gdown --id 1AeNCnN8nOQI2q3p7kpeht2y6Aa95eHmT --output other_food.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AeNCnN8nOQI2q3p7kpeht2y6Aa95eHmT\n",
            "To: /content/other_food.zip\n",
            "348MB [00:04, 71.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E8zBbzMAPak"
      },
      "source": [
        "!unzip other_food.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ra8_jxAUhk",
        "outputId": "a6761d90-db25-415d-efa8-dbf7295be48b"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mother_food\u001b[0m/  other_food.zip  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZK_TRSB_O1u"
      },
      "source": [
        "import pathlib\n",
        "img_dir = 'other_food'\n",
        "data_dir = pathlib.Path(img_dir)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nHc8zjq_bMA",
        "outputId": "a52427d9-0489-4981-c2f2-49f5f086adfb"
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ghZ65HxfMp",
        "outputId": "a04e38cf-7c12-450f-ca72-1120f39ef657"
      },
      "source": [
        "categories = ['beans', 'pizzas', 'fried_chickens']\n",
        "np_classes = len(categories)\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "\n",
        "pixel = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, beans in enumerate(categories):\n",
        "    img_dir_detail = img_dir + \"/\" + beans\n",
        "    files = glob.glob(img_dir_detail+\"/*.jpg\")\n",
        "\n",
        "\n",
        "    for i, f in enumerate(files):\n",
        "        try:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert(\"RGB\")\n",
        "            img = img.resize((image_w, image_h))\n",
        "            data = np.asarray(img)\n",
        "            #Y는 0 아니면 1이니까 idx값으로 넣는다.\n",
        "            X.append(data)\n",
        "            y.append(idx)\n",
        "            if i % 300 == 0:\n",
        "                print(beans, \" : \", f)\n",
        "        except:\n",
        "            print(beans, str(i)+\" 번째에서 에러 \")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beans  :  other_food/beans/Img_025_0620.jpg\n",
            "beans  :  other_food/beans/Img_025_0729.jpg\n",
            "beans  :  other_food/beans/Img_025_0451.jpg\n",
            "beans  :  other_food/beans/Img_025_0390.jpg\n",
            "pizzas  :  other_food/pizzas/Img_027_0430.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pizzas  :  other_food/pizzas/Img_027_0169.jpg\n",
            "pizzas  :  other_food/pizzas/Img_027_0874.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pizzas  :  other_food/pizzas/Img_027_0939.jpg\n",
            "fried_chickens  :  other_food/fried_chickens/Img_028_0193.jpg\n",
            "fried_chickens  :  other_food/fried_chickens/Img_028_0685.jpg\n",
            "fried_chickens  :  other_food/fried_chickens/Img_028_0621.jpg\n",
            "fried_chickens  :  other_food/fried_chickens/Img_028_0047.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roE-T0DAyA63",
        "outputId": "f5448ecf-8857-4d74-a5fb-fef97be28528"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(y)\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
        "\n",
        "xy = (X_train, X_test, Y_train, Y_test)\n",
        "np.save(\"numpy_data/binary_image_data.npy\", xy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AWcphNVyIzT"
      },
      "source": [
        "## 모델 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mysup-CpyKes"
      },
      "source": [
        "이제 훈련을 시작한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3anuQUUyL7C"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.python.keras.backend as K"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h-OXh-PyOlR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = np.load(\"numpy_data/binary_image_data.npy\", allow_pickle=True)\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[0])\n",
        "print(np.bincount(y_train))\n",
        "print(np.bincount(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pguHTReybYp"
      },
      "source": [
        "image_w = 64\n",
        "image_h = 64\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    model_dir = './model'\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.mkdir(model_dir)\n",
        "    model_path = model_dir + \"/dog_cat_classify.model\"\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VI-qA5AycJ_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU_Lz4JKygZv"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.15, callbacks=[checkpoint, early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlWWmTvyyjQx"
      },
      "source": [
        "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UjNW3pNyjbT"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss', 'acc', 'val_acc'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmMtFtSIyoxD"
      },
      "source": [
        "## 모델 정확성 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSat_SXJyvYn"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bdO2INyjni"
      },
      "source": [
        "seed = 5\n",
        "tf.set_random_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "caltech_dir = './binary_img_data/img_test'\n",
        "\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(caltech_dir+\"/*/*.*\")\n",
        "for i, f in enumerate(files):\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "X = X.astype(float) / 255\n",
        "model = load_model('./model/dog_cat_classify.model')\n",
        "\n",
        "prediction = model.predict(X)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "cnt = 0\n",
        "for i in prediction:\n",
        "    if i >= 0.5: print(\"해당 \" + filenames[cnt].split(\"\\\\\")[1] + filenames[cnt].split(\"\\\\\")[2] + \"  이미지는 개 로 추정됩니다.\")\n",
        "    else : print(\"해당 \" + filenames[cnt].split(\"\\\\\")[1] + filenames[cnt].split(\"\\\\\")[2] + \"  이미지는 고양이 으로 추정됩니다.\")\n",
        "    cnt += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}